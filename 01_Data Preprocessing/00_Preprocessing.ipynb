{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyedflib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_dict(patient:str, root_path:str) -> dict:\n",
    "    '''\n",
    "    Creates dictionary of files and seizures of a patient\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    patient : str\n",
    "        identifier of the patient\n",
    "    root_path : str\n",
    "        path to the root directory of the scalp database\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        dictionary that contains the list of channels and times of seizures for each file\n",
    "    '''\n",
    "    info_file = open(root_path + patient + '/' + patient + '-summary.txt','r').readlines() # Open txt file\n",
    "    patient_dict = {'channel_list': []} # Create empty dictionary\n",
    "    for line in info_file: # Iterate over lines in txt file\n",
    "        if(re.findall(r'(File Name: )\\D*\\d*(_)\\d*(.edf)', line)): # If information about next file\n",
    "            file = re.findall(r'(?:chb)\\d*_\\d*(?:.edf)', line)[0] # Get filename\n",
    "            patient_dict[file] = {'seizure_start': [], 'seizure_end': []} # Create new sub-dict for new file\n",
    "        elif(re.findall(r'Channel \\d+', line)): # If channel description\n",
    "            patient_dict['channel_list'].append(str(re.findall(r'Channel\\s\\d+:\\s(\\S*)', line)[0])) # Add channels to list\n",
    "        elif(re.findall(r'Seizure Start Time|Seizure \\d+ Start Time', line)): # If seizure start timestamp\n",
    "            patient_dict[file]['seizure_start'].append(int(re.findall(r'(\\d+)\\sseconds', line)[0])) # Add seizure start to list\n",
    "        elif(re.findall(r'Seizure End Time|Seizure \\d+ End Time', line)): # If seizure end timestamp\n",
    "            patient_dict[file]['seizure_end'].append(int(re.findall(r'(\\d+)\\sseconds', line)[0])) # Add seizure end to list\n",
    "    return patient_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labeled_file(file_path:str, channel_list:list, patient_dict:dict) -> pd.DataFrame:\n",
    "    '''\n",
    "    Converts a single file from edf-format to a pandas DataFrame and adds a label if a seizure is present\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        relative path to the file\n",
    "    channel_list : list\n",
    "        list of the requested channels names\n",
    "    patient_dict : dict\n",
    "        dict that contains the seizure information for each file of the patient\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        pandas DataFrame that contains the requested channels with seizure labels\n",
    "    '''\n",
    "    edf_file = pyedflib.EdfReader(file_path) # Read edf file\n",
    "    if not set(channel_list).issubset(set(edf_file.getSignalLabels())): # Check if all requested channels are present\n",
    "        raise ValueError(\"File \" + file_path + \" does not contain requested channels!\") # Raise error if not\n",
    "    signal_data = np.zeros((edf_file.getNSamples()[0], len(channel_list))) # Create empty array for data\n",
    "    for i, channel in enumerate(channel_list): # Iterate over channels\n",
    "        signal_data[:, i] = edf_file.readSignal(edf_file.getSignalLabels().index(channel)) # Add channel data to array\n",
    "    dataframe = pd.DataFrame(signal_data, columns=channel_list).astype('float32') # Create a dataframe from array\n",
    "    dataframe[\"seconds\"] = np.floor(np.linspace(0, len(dataframe)/edf_file.getSampleFrequencies()[0], len(dataframe), endpoint=False)).astype('uint16') # Add seconds column\n",
    "    file_name = re.findall(r'([^\\/]+$)', file_path)[-1] # Get name of file\n",
    "    seizure_start_list = patient_dict.get(file_name).get(\"seizure_start\") # Get list of seizure starts for file\n",
    "    seizure_end_list = patient_dict.get(file_name).get(\"seizure_end\") # Get list of seizure ends for file\n",
    "    dataframe[\"seizure\"] = 0 # Create new column for seizure labels\n",
    "    if(len(seizure_start_list) > 0): # If seizures are present in file\n",
    "        for seizure in range(len(seizure_start_list)): # Iterate over seizures\n",
    "            start_second = seizure_start_list[seizure] # Get current start of seizure\n",
    "            end_second = seizure_end_list[seizure] # Get current end of seizure\n",
    "            dataframe.loc[dataframe[\"seconds\"].between(start_second, end_second), \"seizure\"] = 1 # Label timeframe of seizure\n",
    "    dataframe = dataframe.drop(columns=[\"seconds\"]) # Drop seconds column\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complete_patient_data(patient:str, channel_list:list, root_path:str) -> pd.DataFrame:\n",
    "    '''\n",
    "    Creates a pandas DataFrame that contains all requested channels of the complete eeg data of a patient\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    patient : str\n",
    "        identifier of the patient\n",
    "    channel_list : list\n",
    "        list of the requested channels names\n",
    "    root_path: str\n",
    "        path to the root directory of the scalp database\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        pandas DataFrame that contains the complete labeled eeg data of one patient\n",
    "    '''\n",
    "    parent_path = root_path + patient # Get path of patients parent directory\n",
    "    all_patient_files = sorted(glob.glob(os.path.join(parent_path , (\"*.edf\")))) # Get list of patients files\n",
    "    all_patient_files = [ x for x in all_patient_files if \"+\" not in x ] # Clean file list\n",
    "    patient_dict = get_patient_dict(patient=patient, root_path=root_path) # Get dict of patient data information\n",
    "    concat_list = [] # Create empty list for files\n",
    "    bar = tqdm(total=len(all_patient_files)) # Create progress bar\n",
    "    for file in all_patient_files: # Iterate over all files\n",
    "        try:\n",
    "            concat_list.append(get_labeled_file(file_path=file, channel_list=channel_list, patient_dict=patient_dict)) # Get labeled dataframe of file\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        bar.update(1) # Update progress bar\n",
    "    bar.close() # Close progress bar\n",
    "    dataframe = pd.concat(concat_list, axis=0, ignore_index=True) # Combine all dataframes into one\n",
    "    dataframe[\"patient\"] = patient # Create column with patient identifier\n",
    "    dataframe[\"timestamp\"] = pd.date_range('1970-01-01 00:00:00', freq='3906250N', periods=len(dataframe)) # Add timestamp for later resampling\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_dataframe(dataframe:pd.DataFrame, resample_freq:str, time_col:str) -> pd.DataFrame:\n",
    "    '''\n",
    "    Resamples a pandas DataFrame to the desired frequency\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "   dataframe : pd.DataFrame\n",
    "        Dataframe to be resampled\n",
    "    resample_freq : str\n",
    "        Target data frequency\n",
    "    time_col : str\n",
    "        Column that contains the timestamp\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        pandas DataFrame that contains the resampled data\n",
    "    '''\n",
    "    resampled = dataframe.resample(rule=resample_freq, on=time_col).agg(\"first\")\n",
    "    resampled = resampled.reset_index(drop=True)\n",
    "    return resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalp_database_to_dataframe(patient_list:list, channel_list:list, root_path:str):\n",
    "    '''\n",
    "    Creates a pandas DataFrame that contains the complete data of one patient and saves the dataframe\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    patient_list : list\n",
    "        list of all patient identifiers\n",
    "    channel_list : list\n",
    "        list of the requested channels names\n",
    "    root_path: str\n",
    "        path to the root directory of the scalp database\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        pandas DataFrame that contains the complete labeled eeg data of one patient\n",
    "    '''\n",
    "    for patient in patient_list:\n",
    "        print(\"Processing Patient: \" + patient)\n",
    "        try:\n",
    "            temp_df = get_complete_patient_data(patient, channel_list, root_path) # Create dataframe that contains the labeled data of a patient\n",
    "            print(\"Resample Data\")\n",
    "            temp_df_resampled = resample_dataframe(temp_df, '10ms', 'timestamp') # Resample Dataset\n",
    "            temp_df_resampled.to_pickle('../00_Data/Dataframes/' + patient + '.pkl') # Store dataframe as a pickel\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_channels(patient_list:list, root_path:str) -> list:\n",
    "    '''\n",
    "    Creates a list of channels present for all patients in all files\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    patient_list : list\n",
    "        list of all patient identifiers\n",
    "    root_path: str\n",
    "        path to the root directory of the scalp database\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        list that contains the channels that are present for all files\n",
    "    '''\n",
    "    channel_list = []\n",
    "    patients = patient_list\n",
    "    for patient in patients:\n",
    "        parent_path = root_path + patient\n",
    "        all_patient_files = sorted(glob.glob(os.path.join(parent_path , (\"*.edf\"))))\n",
    "        all_patient_files = [ x for x in all_patient_files if \"+\" not in x ]\n",
    "        for file in all_patient_files:\n",
    "            temp_file = pyedflib.EdfReader(file)\n",
    "            channel_list.append(temp_file.getSignalLabels())\n",
    "    elements_in_all = list(set.intersection(*map(set, channel_list)))\n",
    "    return elements_in_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '../00_Data/chb-mit-scalp-eeg-database-1.0.0/'\n",
    "all_patients = sorted([patient for patient in os.listdir(root_path) if re.match(r'(chb)\\d+', patient)])\n",
    "all_patients.remove(\"chb12\")\n",
    "# channels = ['FP1-F7', 'C3-P3', 'C4-P4', 'CZ-PZ', 'F3-C3', 'F4-C4', 'F7-T7', 'F8-T8', 'FP1-F3', 'FP2-F4', 'FP2-F8', 'FT10-T8', 'FT9-FT10', 'FZ-CZ', 'P3-O1', 'P4-O2', 'P7-O1', 'P7-T7', 'P8-O2', 'T7-FT9', 'T7-P7', 'T8-P8-0', 'T8-P8-1']\n",
    "# channels = get_valid_channels(patient_list=all_patients, root_path=root_path)\n",
    "channels = get_valid_channels(patient_list=all_patients, root_path=root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalp_database_to_dataframe(patient_list=[all_patients[10]], channel_list=channels, root_path=root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../00_Data/Dataframes/chb11.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_time_windows(dataframe:pd.DataFrame, window_length:int, id_column:str, label_column:str, balance_ratio:float, step:int, extract_series:bool, random_state:int):\n",
    "    unique_ids = dataframe[id_column].unique()\n",
    "    for id in unique_ids:\n",
    "        print(\"Processing patient: \" + str(id))\n",
    "        index_positive = list(dataframe[(dataframe[id_column] == id) & (dataframe[label_column] == 1)].index.values)[::step]\n",
    "        index_negative = dataframe[((dataframe[id_column] == id) & (dataframe[label_column] == 0))].index\n",
    "        random.seed(random_state)\n",
    "        index_negative_sample = random.sample(list(index_negative), int(len(index_positive) * balance_ratio))\n",
    "        sample_indices = list(index_positive + index_negative_sample)\n",
    "        X = []\n",
    "        y = []\n",
    "        bar = tqdm(total=len(sample_indices))\n",
    "        i = 0\n",
    "        for index in sample_indices:\n",
    "            end_index = index + window_length\n",
    "            if (end_index <= len(dataframe)):\n",
    "                if(dataframe[id_column].iloc[index] == dataframe[id_column].iloc[end_index]):\n",
    "                    seq_x = dataframe.drop(columns=[id_column, label_column]).iloc[index:end_index].values.tolist()\n",
    "                    if extract_series:\n",
    "                        seq_y = dataframe[label_column].iloc[index:end_index]\n",
    "                    else:\n",
    "                        seq_y = dataframe[label_column].iloc[end_index]\n",
    "                    X.append(seq_x)\n",
    "                    y.append(seq_y)\n",
    "            bar.update(1)\n",
    "            i += 1\n",
    "        bar.close()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing patient: chb11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4045/4045 [15:51<00:00,  4.25it/s]  \n"
     ]
    }
   ],
   "source": [
    "features, labels = create_balanced_time_windows(df, 10000, \"patient\", \"seizure\", 1.5, 100, False, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4044"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_labels = np.array(labels)\n",
    "np_features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('../test', label=np_labels, features=np_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 1 of Window Generation\n",
    "# Issues:\n",
    "#   - OOM-Exception\n",
    "#   - Extremely ineffecient for big data\n",
    "#   - Very imbalanced data\n",
    "\n",
    "\n",
    "# def create_sliding_windows(dataframe:pd.DataFrame, window_size:int, id_col:str, label_col:str) -> tuple:\n",
    "#     \"\"\"\n",
    "#     Function for the creation of time windows of certain size\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     dataframe : pd.DataFrame\n",
    "#         Dataframe containing all features and target variable as well as a unique identifier\n",
    "#     window_size : int\n",
    "#         Number of timesteps in a timewindow\n",
    "#     id_col : str\n",
    "#         Name of the column that contains the ids\n",
    "#     label_col : str\n",
    "#         Name of the column that is to predicted\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     X : np.array\n",
    "#         Array that contains all of the features of each time window\n",
    "#     y : np.array\n",
    "#         Array that contains all of the labels of each time window\n",
    "#     \"\"\"\n",
    "#     X, y = list(), list() # Create empty lists for X and y\n",
    "#     unique_ids = dataframe[id_col].unique()\n",
    "#     bar = tqdm(total=(len(dataframe) - window_size + 1))\n",
    "#     for i in unique_ids:\n",
    "#         temp_df = dataframe.loc[dataframe[id_col] == i].reset_index().drop(columns=\"index\")\n",
    "#         for n in range(len(temp_df)): # Iterate over rows of temporary dataframe\n",
    "#             end_ix = n + window_size # Calculate last idx of time window\n",
    "#             if (end_ix <= len(temp_df)): # If last idx is still within temporary dataframe\n",
    "#                 seq_x = temp_df.drop(columns=[id_col, label_col])[n:end_ix].values.tolist()\n",
    "#                 seq_y = temp_df.loc[end_ix][label_col]\n",
    "#                 X.append(seq_x) # Append X of current time window to global list\n",
    "#                 y.append(seq_y) # Append y of current time window to global list\n",
    "#             bar.update(1)\n",
    "#     bar.close()\n",
    "#     X = np.array(X) # Create array from global list of X\n",
    "#     y = np.float_(np.array(y)) # Create array of type float from global list of y\n",
    "#     return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 2 of Window Generation\n",
    "# Issues\n",
    "#   - Still ineffecient\n",
    "#   - Unbalanced data\n",
    "\n",
    "# def create_sliding_windows_step(dataframe:pd.DataFrame, window_size:int, id_col:str, label_col:str, step:int, y_series:bool) -> tuple:\n",
    "#     \"\"\"\n",
    "#     Function for the creation of time windows of certain size\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     dataframe : pd.DataFrame\n",
    "#         Dataframe containing all features and target variable as well as a unique identifier\n",
    "#     window_size : int\n",
    "#         Number of timesteps in a timewindow\n",
    "#     id_col : str\n",
    "#         Name of the column that contains the ids\n",
    "#     label_col : str\n",
    "#         Name of the column that is to predicted\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     X : np.array\n",
    "#         Array that contains all of the features of each time window\n",
    "#     y : np.array\n",
    "#         Array that contains all of the labels of each time window\n",
    "#     \"\"\"\n",
    "#     X, y = list(), list() # Create empty lists for X and y\n",
    "#     unique_ids = dataframe[id_col].unique()\n",
    "#     bar = tqdm(total=len(range(0, len(dataframe), step)))\n",
    "#     for i in unique_ids:\n",
    "#         temp_df = dataframe.loc[dataframe[id_col] == i].reset_index().drop(columns=\"index\")\n",
    "#         for n in range(0, len(temp_df), step): # Iterate over rows of temporary dataframe\n",
    "#             end_ix = n + window_size # Calculate last idx of time window\n",
    "#             if (end_ix <= len(temp_df)): # If last idx is still within temporary dataframe\n",
    "#                 seq_x = temp_df.drop(columns=[id_col, label_col])[n:end_ix].values.tolist()\n",
    "#                 if y_series:\n",
    "#                     seq_y = temp_df.loc[n:end_ix][label_col].values.tolist()\n",
    "#                 else:\n",
    "#                     seq_y = temp_df.loc[end_ix][label_col]\n",
    "#                 X.append(seq_x) # Append X of current time window to global list\n",
    "#                 y.append(seq_y) # Append y of current time window to global list\n",
    "#             bar.update(1)\n",
    "#     bar.close()\n",
    "#     X = np.array(X) # Create array from global list of X\n",
    "#     y = np.float_(np.array(y)) # Create array of type float from global list of y\n",
    "#     return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 3 of Window Generation\n",
    "# Issues\n",
    "#   - Memmap has size of >100GB\n",
    "\n",
    "# def create_balanced_time_windows(dataframe:pd.DataFrame, window_length:int, id_column:str, label_column:str, balance_ratio:float, extract_series:bool, random_state:int):\n",
    "#     unique_ids = dataframe[id_column].unique()\n",
    "#     for id in unique_ids:\n",
    "#         print(\"Processing patient: \" + str(id))\n",
    "#         index_positive = dataframe[(dataframe[id_column] == id) & (dataframe[label_column] == 1)].index\n",
    "#         index_negative = dataframe[((dataframe[id_column] == id) & (dataframe[label_column] == 0))].index\n",
    "#         random.seed(random_state)\n",
    "#         index_negative_sample = random.sample(list(index_negative), int(len(index_positive) * float(balance_ratio)))\n",
    "#         sample_indices = index_positive + index_negative_sample\n",
    "#         X = np.memmap('../00_Data/Dataframes/' + str(id) + '_features.npy', np.float32, mode='w+', shape=(len(sample_indices), window_length, 18))\n",
    "#         if extract_series:\n",
    "#             y = np.memmap('../00_Data/Dataframes/' + str(id) + '_label.npy', np.int16, mode='w+', shape=(len(sample_indices), window_length))\n",
    "#         else:\n",
    "#             y = np.memmap('../00_Data/Dataframes/' + str(id) + '_label.npy', np.int16, mode='w+', shape=(len(sample_indices), 1))\n",
    "#         bar = tqdm(total=len(sample_indices))\n",
    "#         i = 0\n",
    "#         for index in sample_indices:\n",
    "#             end_index = index + window_length # Calculate last idx of time window\n",
    "#             if (end_index <= len(dataframe)):\n",
    "#                 if(dataframe[id_column].iloc[index] == dataframe[id_column].iloc[end_index]):\n",
    "#                     seq_x = dataframe.drop(columns=[id_column, \"timestamp\", label_column]).iloc[index:end_index].values.tolist()\n",
    "#                     if extract_series:\n",
    "#                         seq_y = dataframe[label_column].iloc[index:end_index]\n",
    "#                     else:\n",
    "#                         seq_y = dataframe[label_column].iloc[end_index]\n",
    "#                     X[i] = seq_x # Append X of current time window to global list\n",
    "#                     y[i] = seq_y # Append y of current time window to global list\n",
    "#             bar.update(1)\n",
    "#             i += 1\n",
    "#         bar.close()\n",
    "#     return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
