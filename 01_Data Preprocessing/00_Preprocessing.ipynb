{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing of the CHB-MIT Scalp Database\n",
    "This notebook contains the code for the creation of a dataset of labeled time windows for seizure detection based on the CHB-MIT Scalp EEG Database. <br>\n",
    "1. [Imports](#1-imports)\n",
    "2. [Define Functions](#2-define-functions) <br>\n",
    "3. [Generate Data](#3-generate-data)\n",
    "\n",
    "\n",
    "## Dataset Description:\n",
    "Recordings, grouped into 23 cases, were collected from 22 subjects (5 males, ages 3–22; and 17 females, ages 1.5–19). (Case chb21 was obtained 1.5 years after case chb01, from the same female subject.) The file SUBJECT-INFO contains the gender and age of each subject. (Case chb24 was added to this collection in December 2010, and is not currently included in SUBJECT-INFO.)\n",
    "\n",
    "Each case (chb01, chb02, etc.) contains between 9 and 42 continuous .edf files from a single subject. Hardware limitations resulted in gaps between consecutively-numbered .edf files, during which the signals were not recorded; in most cases, the gaps are 10 seconds or less, but occasionally there are much longer gaps. In order to protect the privacy of the subjects, all protected health information (PHI) in the original .edf files has been replaced with surrogate information in the files provided here. Dates in the original .edf files have been replaced by surrogate dates, but the time relationships between the individual files belonging to each case have been preserved. In most cases, the .edf files contain exactly one hour of digitized EEG signals, although those belonging to case chb10 are two hours long, and those belonging to cases chb04, chb06, chb07, chb09, and chb23 are four hours long; occasionally, files in which seizures are recorded are shorter.\n",
    "\n",
    "All signals were sampled at 256 HZ with 16-bit resolution. Most files contain 23 EEG signals (24 or 26 in a few cases). The International 10-20 system of EEG electrode positions and nomenclature was used for these recordings. In a few records, other signals are also recorded, such as an ECG signal in the last 36 files belonging to case chb04 and a vagal nerve stimulus (VNS) signal in the last 18 files belonging to case chb09. In some cases, up to 5 “dummy” signals (named \"-\") were interspersed among the EEG signals to obtain an easy-to-read display format; these dummy signals can be ignored.\n",
    "\n",
    "The file RECORDS contains a list of all 664 .edf files included in this collection, and the file RECORDS-WITH-SEIZURES lists the 129 of those files that contain one or more seizures. In all, these records include 198 seizures (182 in the original set of 23 cases); the beginning ([) and end (]) of each seizure is annotated in the .seizure annotation files that accompany each of the files listed in RECORDS-WITH-SEIZURES. In addition, the files named chbnn-summary.txt contain information about the montage used for each recording, and the elapsed time in seconds from the beginning of each .edf file to the beginning and end of each seizure contained in it. <br>\n",
    "Source:  <a href=\"https://physionet.org/content/chbmit/1.0.0/\">Pyhsionet</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports\n",
    "Import requiered libraries. <br>\n",
    "External packages can be installed via the `pip install -r requirements.txt` command or the notebook-cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import built-in libraries\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "import subprocess\n",
    "\n",
    "# Import data science libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import library for processing edf-files\n",
    "import pyedflib\n",
    "\n",
    "# Import progress bar library\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not(os.path.exists(\"../00_Data/chb-mit-scalp-eeg-database-1.0.0/\"))):\n",
    "    print(\"File not found. Download started... (this might take a while):\")\n",
    "    subprocess.call(['sh', '../bin/download_and_unzip_data.sh'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Functions\n",
    "The following functions are needed for the processing of the raw eeg data. <br>\n",
    "Each functions is documented with docstring and every line is commented."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 get_patient_dict()\n",
    "This function reads the `summary.txt`-file that is located in the folder of every patient. It contains the channel-mapping, start-, and end-time of each file as well as the start and end of each individual seizure. This function parses every line and creates a dictionary that can be used for labeling the final dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_dict(patient:str, root_path:str) -> dict:\n",
    "    '''\n",
    "    Creates dictionary of files and seizures of a patient\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    patient : str\n",
    "        identifier of the patient\n",
    "    root_path : str\n",
    "        path to the root directory of the scalp database\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        dictionary that contains the list of channels and times of seizures for each file\n",
    "    '''\n",
    "    info_file = open(root_path + patient + '/' + patient + '-summary.txt','r').readlines() # Open txt file\n",
    "    patient_dict = {'channel_list': []} # Create empty dictionary\n",
    "    for line in info_file: # Iterate over lines in txt file\n",
    "        if(re.findall(r'((File Name: )\\D*\\d*(_)\\d*(.edf)|(File Name: )\\D*\\d*\\D(_)\\d*(.edf))', line)): # If information about next file\n",
    "            file = re.findall(r'((?:chb)\\d*_\\d*(?:.edf)|(?:chb)\\d*\\D_\\d*(?:.edf))', line)[0] # Get filename\n",
    "            patient_dict[file] = {'seizure_start': [], 'seizure_end': []} # Create new sub-dict for new file\n",
    "        elif(re.findall(r'Channel \\d+', line)): # If channel description\n",
    "            patient_dict['channel_list'].append(str(re.findall(r'Channel\\s\\d+:\\s(\\S*)', line)[0])) # Add channels to list\n",
    "        elif(re.findall(r'Seizure Start Time|Seizure \\d+ Start Time', line)): # If seizure start timestamp\n",
    "            patient_dict[file]['seizure_start'].append(int(re.findall(r'(\\d+)\\sseconds', line)[0])) # Add seizure start to list\n",
    "        elif(re.findall(r'Seizure End Time|Seizure \\d+ End Time', line)): # If seizure end timestamp\n",
    "            patient_dict[file]['seizure_end'].append(int(re.findall(r'(\\d+)\\sseconds', line)[0])) # Add seizure end to list\n",
    "    return patient_dict\n",
    "# Based on the approach of: https://github.com/Eldave93/Seizure-Detection-Tutorials/blob/master/Extra_01_Assemble_Feature_DataFrames.ipynb (last access on: 08.06.2023)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 get_labeled_file()\n",
    "This function reads one `.edf` file of a patient and converts it into a pandas DataFrame. The time series data is labeled via the the, in the previous function created dictionary, if a seizure is present and additional patient information is added. <br>\n",
    "Because the seizures are given as seconds from the beginning of a file, a new temporary column with seconds in respect to the sampling frequency is added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labeled_file(file_path:str, channel_list:list, patient_dict:dict) -> pd.DataFrame:\n",
    "    '''\n",
    "    Converts a single file from edf-format to a pandas DataFrame and adds a label if a seizure is present\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        relative path to the file\n",
    "    channel_list : list\n",
    "        list of the requested channels names\n",
    "    patient_dict : dict\n",
    "        dict that contains the seizure information for each file of the patient\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        pandas DataFrame that contains the requested channels with seizure labels\n",
    "    '''\n",
    "    edf_file = pyedflib.EdfReader(file_path) # Read edf file\n",
    "    if not set(channel_list).issubset(set(edf_file.getSignalLabels())): # Check if all requested channels are present\n",
    "        raise ValueError(\"File \" + file_path + \" does not contain requested channels!\") # Raise error if not\n",
    "    signal_data = np.zeros((edf_file.getNSamples()[0], len(channel_list))) # Create empty array for data\n",
    "    for i, channel in enumerate(channel_list): # Iterate over channels\n",
    "        signal_data[:, i] = edf_file.readSignal(edf_file.getSignalLabels().index(channel)) # Add channel data to array\n",
    "    dataframe = pd.DataFrame(signal_data, columns=channel_list).astype('float32') # Create a dataframe from array\n",
    "    dataframe[\"seconds\"] = np.floor(np.linspace(0, len(dataframe)/edf_file.getSampleFrequencies()[0], len(dataframe), endpoint=False)).astype('uint16') # Add seconds column\n",
    "    file_name = re.findall(r'([^\\/]+$)', file_path)[-1] # Get name of file\n",
    "    seizure_start_list = patient_dict.get(file_name).get(\"seizure_start\") # Get list of seizure starts for file\n",
    "    seizure_end_list = patient_dict.get(file_name).get(\"seizure_end\") # Get list of seizure ends for file\n",
    "    dataframe[\"seizure\"] = 0 # Create new column for seizure labels\n",
    "    if(len(seizure_start_list) > 0): # If seizures are present in file\n",
    "        for seizure in range(len(seizure_start_list)): # Iterate over seizures\n",
    "            start_second = seizure_start_list[seizure] # Get current start of seizure\n",
    "            end_second = seizure_end_list[seizure] # Get current end of seizure\n",
    "            dataframe.loc[dataframe[\"seconds\"].between(start_second, end_second), \"seizure\"] = 1 # Label timeframe of seizure\n",
    "    dataframe = dataframe.drop(columns=[\"seconds\"]) # Drop seconds column\n",
    "    dataframe[\"file_name\"] = file_name # Add column with file namen for later time window processing\n",
    "    return dataframe\n",
    "# Based on the approach of: https://github.com/Eldave93/Seizure-Detection-Tutorials/blob/master/Extra_01_Assemble_Feature_DataFrames.ipynb (last access on: 08.06.2023)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 get_complete_patient_data()\n",
    "The target output of this function is a dataframe, that contains the complete, labeled and enhanced data of one patient. In addition, a column with a timestamp is added for optinal later resampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complete_patient_data(patient:str, channel_list:list, root_path:str) -> pd.DataFrame:\n",
    "    '''\n",
    "    Creates a pandas DataFrame that contains all requested channels of the complete eeg data of a patient\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    patient : str\n",
    "        identifier of the patient\n",
    "    channel_list : list\n",
    "        list of the requested channels names\n",
    "    root_path: str\n",
    "        path to the root directory of the scalp database\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        pandas DataFrame that contains the complete labeled eeg data of one patient\n",
    "    '''\n",
    "    parent_path = root_path + patient # Get path of patients parent directory\n",
    "    all_patient_files = sorted(glob.glob(os.path.join(parent_path , (\"*.edf\")))) # Get list of patients files\n",
    "    all_patient_files = [ x for x in all_patient_files if \"+\" not in x ] # Clean file list\n",
    "    patient_dict = get_patient_dict(patient=patient, root_path=root_path) # Get dict of patient data information\n",
    "    concat_list = [] # Create empty list for files\n",
    "    bar = tqdm(total=len(all_patient_files)) # Create progress bar\n",
    "    for file in all_patient_files: # Iterate over all files\n",
    "        try:\n",
    "            concat_list.append(get_labeled_file(file_path=file, channel_list=channel_list, patient_dict=patient_dict)) # Get labeled dataframe of file\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        bar.update(1) # Update progress bar\n",
    "    bar.close() # Close progress bar\n",
    "    dataframe = pd.concat(concat_list, axis=0, ignore_index=True) # Combine all dataframes into one\n",
    "    dataframe[\"patient\"] = patient # Create column with patient identifier\n",
    "    dataframe[\"timestamp\"] = pd.date_range('1970-01-01 00:00:00', freq='3906250N', periods=len(dataframe)) # Add timestamp for later resampling\n",
    "    subject_info = pd.read_csv(root_path + '/SUBJECT-INFO', delimiter='\\s+').drop(columns=[\"(years)\"]).set_index(\"Case\", drop=True).loc[patient].to_dict() # Get subject infor as dict\n",
    "    dataframe[\"age\"] = float(subject_info.get(\"Age\")) # Add column with subject age\n",
    "    if(subject_info.get(\"Gender\")=='F'): # If subject is female\n",
    "        dataframe[\"gender\"] = 1 # Add column with encoded gender\n",
    "    elif(subject_info.get(\"Gender\")=='M'): # If subject is male\n",
    "        dataframe[\"gender\"] = 0 # Add column with encoded gender\n",
    "    else: # If subject gender is not defined\n",
    "        dataframe[\"gender\"] = -1 # Add column with arbitrary value\n",
    "    return dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 resample_dataframe()\n",
    "This very simple function subsamples a dataframe to the desired frequency and drops the old index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_dataframe(dataframe:pd.DataFrame, resample_freq:str, time_col:str) -> pd.DataFrame:\n",
    "    '''\n",
    "    Resamples a pandas DataFrame to the desired frequency\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "   dataframe : pd.DataFrame\n",
    "        dataframe to be resampled\n",
    "    resample_freq : str\n",
    "        target data frequency\n",
    "    time_col : str\n",
    "        column that contains the timestamp\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        pandas DataFrame that contains the resampled data\n",
    "    '''\n",
    "    resampled_df = dataframe.resample(rule=resample_freq, on=time_col).agg(\"first\") # Resample dataframe and select the first value\n",
    "    resampled_df = resampled_df.reset_index(drop=True) # Drop timestamp index\n",
    "    return resampled_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 create_balanced_time_windows()\n",
    "This function is the 4th iteration of a sliding time window generation method. The following problems must be adressed:\n",
    "- Memory limitations: The generation of long overlapping time windows is very memory intensive and can very quickly lead to OEM-Exceptions\n",
    "- Processing time: Depending on the used device, this process can take very long (up to 48h per patient)\n",
    "- Imbalance: The resulting data is extremely imbalanced due to the frequency and length of seizures\n",
    "\n",
    "To solve these issues, the follwing concepts where used:\n",
    "- Memory limitations: Instead of creating all possible time windows for the data, only a subset based on the balance-ratio are extracted\n",
    "- Processing time: This issue is solved by the reduced amount of windows as well as pre-allocating the memory for the numpy Arrays\n",
    "- Imbalance: To adress the imbalance, the data is first split into two sets containg only samples of each label. A random sample of the majority class data is taken based on a defined balance_ratio to avoid a highly imbalance data and reduce the overall amount of windows. \n",
    "\n",
    "Due to the algorithm behind the selection of start indices for the sliding windows, there are no samples where a seizure is beginning to start. Therefore, a window edge-case handeling is added to create additional time windows and supplement the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_time_windows(dataframe:pd.DataFrame, window_length:int, id_column:str, label_column:str, balance_ratio:float, step:int, extract_series:bool, label_max:bool, random_state:int) -> tuple:\n",
    "    '''\n",
    "    Creates sliding time windows based on time series data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "   dataframe : pd.DataFrame\n",
    "        dataframe to be resampled\n",
    "    window_lenth : int\n",
    "        length of the time windows\n",
    "    id_col : str\n",
    "        column that contains the id of the patients\n",
    "    label_col : str\n",
    "        column that contains the label\n",
    "    balance_ratio : float\n",
    "        balance ration bewtween majority and minority class\n",
    "    step : int\n",
    "        step between windows\n",
    "    extract_series : Bool\n",
    "        decides wether y is a series or a single label\n",
    "    label_max : Bool\n",
    "        extract labels based on maximum or average in time window\n",
    "    random_state : int\n",
    "        random state for resampling\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : np.array\n",
    "        array containing the feature values for each window\n",
    "    y : np.array\n",
    "        array containing the label(s) for each window\n",
    "    '''\n",
    "    unique_ids = dataframe[id_column].unique() # Create list of unique ids in dataframe\n",
    "    for id in unique_ids: # Iterate over ids (safety feature)\n",
    "        index_positive = list(dataframe[(dataframe[id_column] == id) & (dataframe[label_column] == 1)].index.values)[::step] # Get indices of all positive samples and apply step\n",
    "        index_negative = dataframe[((dataframe[id_column] == id) & (dataframe[label_column] == 0))].index # Get indices of all negative samples\n",
    "        index_positive_edge_case = [] # Create empty list for ids, that are directly at the beginning of seizures\n",
    "        for idx in index_positive: # Iterate over positive indices\n",
    "            if((idx-window_length)>=0): # If index in dataframe\n",
    "                if(dataframe[label_column].iloc[(idx-window_length)]==0): # If index at the beginning of a seizure\n",
    "                    index_positive_edge_case.append(int(idx-window_length-1)) # Add new index to list\n",
    "        index_positive = index_positive + index_positive_edge_case # Combine positive indices with edge case indices\n",
    "        random.seed(random_state) # Set seed for random\n",
    "        index_negative_sample = random.sample(list(index_negative), int(len(index_positive) * balance_ratio)) # Sample subset of negative indices\n",
    "        sample_indices = list(index_positive + index_negative_sample) # Combine indices lists\n",
    "        X = np.zeros((len(sample_indices), window_length, (len(dataframe.columns)-3)), dtype='float32') # Create empty array for features\n",
    "        if extract_series:\n",
    "            y = np.zeros((len(sample_indices), window_length), dtype='int8') # Create empty array for label series\n",
    "        else:\n",
    "            y = np.zeros((len(sample_indices), 1), dtype='int8') # Create empty array for single labels\n",
    "        bar = tqdm(total=len(sample_indices)) # Create progress bar\n",
    "        i = 0 # Set iteration variable\n",
    "        for index in sample_indices: # Iterate over indices\n",
    "            end_index = index + window_length # Calculate end index of current window\n",
    "            if (end_index <= len(dataframe)): # If window not exceeds the length of the dataframe\n",
    "                if(dataframe[\"file_name\"].iloc[index] == dataframe[\"file_name\"].iloc[end_index]): # If data in window from the same patient (safety feature)\n",
    "                    seq_X = dataframe.drop(columns=[id_column, label_column, \"file_name\"]).iloc[index:end_index].values.tolist() # Create list of feature values in window\n",
    "                    if extract_series: # If a series of labels is to be extraced\n",
    "                        seq_y = dataframe[label_column].iloc[index:end_index].values.tolist() # Create list of label values in window\n",
    "                    else:\n",
    "                        if(label_max):\n",
    "                            seq_y = np.amax(np.array(dataframe[label_column].iloc[index:end_index].values.tolist())) # If seizure anywhere present\n",
    "                        else:\n",
    "                            seq_y = round(np.mean(np.array(dataframe[label_column].iloc[index:end_index].values.tolist()), axis=0)) # Get most present label\n",
    "                    X[i] = seq_X # Add feature window to main list\n",
    "                    y[i] = seq_y # Add label (window) to main list\n",
    "            bar.update(1) # Update progress bar\n",
    "            i += 1 # Increment iteration variable\n",
    "        bar.close() # Close progress bar\n",
    "        X = np.array(X) # Create numpy array from window feature list\n",
    "        y = np.int_(np.array(y)) # Create numpy array from window label list\n",
    "    return X, y\n",
    "# With modifications taken from my bachelor thesis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 scalp_database_to_dataframe()\n",
    "This function is split into two stages and coordinates the processing of the raw patient and eeg data to complete and labeled dataframes as well as the combination of each dataframe to a complete dataset for future training and validation of machine learning models. First, the processing and enhancement of the patient data is executed and a temporary dataframe that contains the complete data of a patient from which the sliding time windows are created and stored in individual temporary files. Following, all individual samples are combined into one big file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalp_database_to_dataframe(patient_list:list, channel_list:list, root_path:str, conf:dict, save_dataframe:bool, save_path:str=\"\") -> tuple:\n",
    "    '''\n",
    "    Creates a pandas DataFrame that contains the complete data of one patient and saves the dataframe\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    patient_list : list\n",
    "        list of all patient identifiers\n",
    "    channel_list : list\n",
    "        list of the requested channels names\n",
    "    root_path : str\n",
    "        path to the root directory of the scalp database\n",
    "    conf : dict\n",
    "        dictionary that contains the configuration data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : np.array\n",
    "        array containing the aggregated feature values for each window of all patients\n",
    "    y : np.array\n",
    "        array containing the aggregated label(s) for each window of all patients\n",
    "    '''\n",
    "    if not os.path.isdir(root_path + '/../Processed-Data'): # Check if processed data folder exists\n",
    "        os.makedirs(root_path + '/../Processed-Data') # Create processed data folder\n",
    "    if not os.path.isdir(root_path + '/../Processed-Data/Temp'): # Check if temp sub-folder exists\n",
    "        os.makedirs(root_path + '/../Processed-Data/Temp') # Create temp sub-folder\n",
    "    for patient in patient_list: # Iterate over patients\n",
    "        print(\"==================================\\n Processing Patient: \" + patient + \" (\" + str(patient_list.index(patient)+1) + \"/\" + str(len(patient_list)) + \")\\n==================================\")\n",
    "        try:\n",
    "            print(\"1. Read raw files & find seizures\")\n",
    "            temp_df = get_complete_patient_data(patient, channel_list, root_path) # Create dataframe that contains the labeled data of a patient\n",
    "            print(\"2. Resample Data\")\n",
    "            temp_df_resampled = resample_dataframe(\n",
    "                dataframe = temp_df, \n",
    "                resample_freq = conf[\"resample\"][\"frequency\"], \n",
    "                time_col = conf[\"resample\"][\"timestamp_column\"]\n",
    "                ) # Resample Dataset\n",
    "            print(\"3. Create Sliding Time Windows\")\n",
    "            X_temp, y_temp = create_balanced_time_windows(\n",
    "                dataframe = temp_df_resampled, \n",
    "                window_length = conf[\"sliding_time_window\"][\"window_length\"], \n",
    "                id_column = \"patient\", \n",
    "                label_column = \"seizure\", \n",
    "                balance_ratio = conf[\"sliding_time_window\"][\"balance_ratio\"], \n",
    "                step = conf[\"sliding_time_window\"][\"window_step\"], \n",
    "                extract_series = conf[\"sliding_time_window\"][\"return_sequences\"], \n",
    "                label_max = conf[\"sliding_time_window\"][\"label_max\"],\n",
    "                random_state = conf[\"sliding_time_window\"][\"random_seed\"]\n",
    "            ) # Create sliding time windows\n",
    "            np.savez_compressed('../00_Data/Processed-Data/Temp/' + str(patient), features=X_temp, labels=y_temp) # Save processed data of one patient as compressed file\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    print(\"==================================\\n Build Complete Data\\n==================================\")\n",
    "    total_len = 0 # Iteration variable for total number of time windows\n",
    "    all_files = sorted(glob.glob(os.path.join('../00_Data/Processed-Data/Temp/' , (\"*.npz\")))) # Get list of all compressed patient data files\n",
    "    for file in all_files: # Iterate over all files\n",
    "        total_len += len(np.load(file)[\"features\"]) # Load comporessed file and add number of windows to variable\n",
    "    X = np.zeros((total_len, X_temp.shape[1], X_temp.shape[2]), dtype='float32') # Create empty array for all feature windows\n",
    "    if(conf[\"sliding_time_window\"][\"return_sequences\"]): # If label sequences are returned\n",
    "        y = np.zeros((total_len, y_temp.shape[1]), dtype='int8') # Create empty array for label sequences\n",
    "    else:\n",
    "        y = np.zeros((total_len, 1), dtype='int8') # Create empty array for window labels\n",
    "    i = 0 # Iteration variable for accessing empty arrays\n",
    "    bar = tqdm(total=len(all_files)) # Create progress bar\n",
    "    for file in all_files: # Iterate over all files again\n",
    "        compressed_data = np.load(file) # Load current file\n",
    "        X_temp = compressed_data[\"features\"] # Extract features from compressed file\n",
    "        y_temp = compressed_data[\"labels\"] # Extract labels from compressed file\n",
    "        for n in range(len(X_temp)): # For each window in file\n",
    "            X[(i+n)] = X_temp[n] # Add window features to global array\n",
    "            y[(i+n)] = y_temp[n] # Add window label(s) to global array\n",
    "        i += len(X_temp) # Increment iteration variable\n",
    "        bar.update(1) # Update progress bar\n",
    "    bar.close() # Close progress bar\n",
    "    if save_dataframe:\n",
    "        print(\"Saving data; Depending on the amount of data, this might take up to 20 minutes!\")\n",
    "        np.savez_compressed(save_path, features=X, labels=y) # Save aggregated data as compressed file\n",
    "        shutil.rmtree(root_path + '/../Processed-Data/Temp') # Delete Temp folder\n",
    "    return X, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 get_valid_channels()\n",
    "Because the data was taken from multiple patients in multiple hospitals and medical instutuions, the used channels and electrodes vary between the patiens or even indivudal files. This functions iterates over all files of all patients and extracts the channels that are present in every instance. This enshures a successful processing of the data and the generation of a complete dataset without any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_channels(patient_list:list, root_path:str) -> list:\n",
    "    '''\n",
    "    Creates a list of channels present for all patients in all files\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    patient_list : list\n",
    "        list of all patient identifiers\n",
    "    root_path: str\n",
    "        path to the root directory of the scalp database\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        list that contains the channels that are present for all files\n",
    "    '''\n",
    "    channel_list = [] # Create empty list for channels\n",
    "    for patient in patient_list: # Iterate over patients\n",
    "        parent_path = root_path + patient # Create path to patient files\n",
    "        all_patient_files = sorted(glob.glob(os.path.join(parent_path , (\"*.edf\")))) # Get list of all patient files\n",
    "        all_patient_files = [ x for x in all_patient_files if \"+\" not in x ] # Get file(s) with channel information\n",
    "        for file in all_patient_files: # Iterate over file(s) with channel information\n",
    "            temp_file = pyedflib.EdfReader(file) # Read edf file\n",
    "            channel_list.append(temp_file.getSignalLabels()) # Create list with all channels from all files\n",
    "    elements_in_all = list(set.intersection(*map(set, channel_list))) # Create set with channels that are present in all files\n",
    "    return elements_in_all"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 get_valid_patients()\n",
    "Because the data was taken from multiple patients in multiple hospitals and medical instutuions, the used channels and electrodes vary between the patiens or even indivudal files. This functions takes an alternative approach and extracts the patients, where all files contain the requested channels. This is also done by an iteration over all patients and files with an extraction of the present channels. This enshures a successful processing of the data and the generation of a complete dataset without any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_patients(patient_list:list, root_path:str, requiered_channels:list):\n",
    "    '''\n",
    "    Creates a list of channels patients where all files contain the requested channels\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    patient_list : list\n",
    "        list of all patient identifiers\n",
    "    root_path : str\n",
    "        path to the root directory of the scalp database\n",
    "    requiered_channels : list\n",
    "        list of channles that are to be extracted\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        list that contains the channels that are present for all files\n",
    "    '''\n",
    "    valid_patients = []\n",
    "    for patient in patient_list:\n",
    "        parent_path = root_path + patient\n",
    "        all_patient_files = sorted(glob.glob(os.path.join(parent_path , (\"*.edf\")))) # Get list of all patient files\n",
    "        all_patient_files = [ x for x in all_patient_files if \"+\" not in x ] # Get file(s) with channel information\n",
    "        requiered_channels_present = []\n",
    "        for file in all_patient_files:\n",
    "            temp_file = pyedflib.EdfReader(file)\n",
    "            if(set(requiered_channels).issubset(temp_file.getSignalLabels())):\n",
    "                requiered_channels_present.append(True)\n",
    "            else:\n",
    "                requiered_channels_present.append(False)\n",
    "        if(False not in requiered_channels_present):\n",
    "            valid_patients.append(patient)\n",
    "    return valid_patients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Data\n",
    "After defining all necessary functions, the training data for the machine learning models can be performed. First, the root path of the raw data as well as a list of all patients is created. Patient chb12 is dropped due to a completely different electrode placement and resulting incompatibility with other files. Next, a selection of either the channels present in all patient files or the patients containing the requested channels must be performed. To ensure a correct and complete data basis for the classification of the EEG data, the second approach was chosen and all channels of the international 10-20 system were applied. <br>\n",
    "\n",
    "**International EEG 10-20 Electrode Placement:** <br>\n",
    "<img src=\"99_Assets/02_Images/EEG_Elektrodenanordnung_nach_10-20_-englisch-TerniMed.jpg\" alt=\"Topomap 10-20 System\" width=\"50%\"/><br>\n",
    "With changes taken from: <a href=\"https://www.ternimed.de/WebRoot/Store2/Shops/62826360/MediaGallery/Bilder/EEG_Elektrodenanordnung_nach_10-20_-englisch-TerniMed.jpg\">Source</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '../00_Data/chb-mit-scalp-eeg-database-1.0.0/'\n",
    "all_patients = sorted([patient for patient in os.listdir(root_path) if re.match(r'(chb)\\d+', patient)])\n",
    "all_patients.remove(\"chb12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels = get_valid_channels(patient_list=all_patients, root_path=root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['F8-T8', 'T7-FT9', 'F4-C4', 'C3-P3', 'P7-T7', 'P7-O1', 'T8-P8', 'FP1-F7', 'P8-O2', 'T7-P7', 'C4-P4', 'FT10-T8', 'P4-O2', 'F7-T7', 'CZ-PZ', 'FP2-F8', 'P3-O1', 'FP1-F3','FP2-F4', 'FZ-CZ', 'F3-C3', 'FT9-FT10']\n",
    "all_patients = get_valid_patients(patient_list=all_patients, root_path=root_path, requiered_channels=channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    'resample':{\n",
    "        'frequency': \"10ms\",\n",
    "        'timestamp_column': \"timestamp\"\n",
    "    },\n",
    "    'sliding_time_window':{\n",
    "       'window_length': 1000,\n",
    "       'balance_ratio': 1.2,\n",
    "       'window_step': 100,\n",
    "       'return_sequences': False,\n",
    "       'label_max': True,\n",
    "       'random_seed': 28\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = scalp_database_to_dataframe(\n",
    "    patient_list=all_patients, \n",
    "    channel_list=channels, \n",
    "    root_path=root_path, \n",
    "    conf=config_dict, \n",
    "    save_dataframe=True, \n",
    "    save_path='../00_Data/Processed-Data/classification_dataset'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Old Functions\n",
    "The following functions were created during the development of the approach, but were improved due to multiple issues. The cells below are only used to demonstrate different approaches and are not used for productive creation of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 1 of Window Generation\n",
    "# Issues:\n",
    "#   - OOM-Exception\n",
    "#   - Extremely ineffecient for big data\n",
    "#   - Very imbalanced data\n",
    "\n",
    "\n",
    "# def create_sliding_windows(dataframe:pd.DataFrame, window_size:int, id_col:str, label_col:str) -> tuple:\n",
    "#     \"\"\"\n",
    "#     Function for the creation of time windows of certain size\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     dataframe : pd.DataFrame\n",
    "#         Dataframe containing all features and target variable as well as a unique identifier\n",
    "#     window_size : int\n",
    "#         Number of timesteps in a timewindow\n",
    "#     id_col : str\n",
    "#         Name of the column that contains the ids\n",
    "#     label_col : str\n",
    "#         Name of the column that is to predicted\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     X : np.array\n",
    "#         Array that contains all of the features of each time window\n",
    "#     y : np.array\n",
    "#         Array that contains all of the labels of each time window\n",
    "#     \"\"\"\n",
    "#     X, y = list(), list() # Create empty lists for X and y\n",
    "#     unique_ids = dataframe[id_col].unique()\n",
    "#     bar = tqdm(total=(len(dataframe) - window_size + 1))\n",
    "#     for i in unique_ids:\n",
    "#         temp_df = dataframe.loc[dataframe[id_col] == i].reset_index().drop(columns=\"index\")\n",
    "#         for n in range(len(temp_df)): # Iterate over rows of temporary dataframe\n",
    "#             end_ix = n + window_size # Calculate last idx of time window\n",
    "#             if (end_ix <= len(temp_df)): # If last idx is still within temporary dataframe\n",
    "#                 seq_x = temp_df.drop(columns=[id_col, label_col])[n:end_ix].values.tolist()\n",
    "#                 seq_y = temp_df.loc[end_ix][label_col]\n",
    "#                 X.append(seq_x) # Append X of current time window to global list\n",
    "#                 y.append(seq_y) # Append y of current time window to global list\n",
    "#             bar.update(1)\n",
    "#     bar.close()\n",
    "#     X = np.array(X) # Create array from global list of X\n",
    "#     y = np.float_(np.array(y)) # Create array of type float from global list of y\n",
    "#     return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 2 of Window Generation\n",
    "# Issues\n",
    "#   - Still ineffecient\n",
    "#   - Unbalanced data\n",
    "\n",
    "# def create_sliding_windows_step(dataframe:pd.DataFrame, window_size:int, id_col:str, label_col:str, step:int, y_series:bool) -> tuple:\n",
    "#     \"\"\"\n",
    "#     Function for the creation of time windows of certain size\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     dataframe : pd.DataFrame\n",
    "#         Dataframe containing all features and target variable as well as a unique identifier\n",
    "#     window_size : int\n",
    "#         Number of timesteps in a timewindow\n",
    "#     id_col : str\n",
    "#         Name of the column that contains the ids\n",
    "#     label_col : str\n",
    "#         Name of the column that is to predicted\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     X : np.array\n",
    "#         Array that contains all of the features of each time window\n",
    "#     y : np.array\n",
    "#         Array that contains all of the labels of each time window\n",
    "#     \"\"\"\n",
    "#     X, y = list(), list() # Create empty lists for X and y\n",
    "#     unique_ids = dataframe[id_col].unique()\n",
    "#     bar = tqdm(total=len(range(0, len(dataframe), step)))\n",
    "#     for i in unique_ids:\n",
    "#         temp_df = dataframe.loc[dataframe[id_col] == i].reset_index().drop(columns=\"index\")\n",
    "#         for n in range(0, len(temp_df), step): # Iterate over rows of temporary dataframe\n",
    "#             end_ix = n + window_size # Calculate last idx of time window\n",
    "#             if (end_ix <= len(temp_df)): # If last idx is still within temporary dataframe\n",
    "#                 seq_x = temp_df.drop(columns=[id_col, label_col])[n:end_ix].values.tolist()\n",
    "#                 if y_series:\n",
    "#                     seq_y = temp_df.loc[n:end_ix][label_col].values.tolist()\n",
    "#                 else:\n",
    "#                     seq_y = temp_df.loc[end_ix][label_col]\n",
    "#                 X.append(seq_x) # Append X of current time window to global list\n",
    "#                 y.append(seq_y) # Append y of current time window to global list\n",
    "#             bar.update(1)\n",
    "#     bar.close()\n",
    "#     X = np.array(X) # Create array from global list of X\n",
    "#     y = np.float_(np.array(y)) # Create array of type float from global list of y\n",
    "#     return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 3 of Window Generation\n",
    "# Issues\n",
    "#   - Memmap has size of >100GB\n",
    "\n",
    "# def create_balanced_time_windows(dataframe:pd.DataFrame, window_length:int, id_column:str, label_column:str, balance_ratio:float, extract_series:bool, random_state:int):\n",
    "#     unique_ids = dataframe[id_column].unique()\n",
    "#     for id in unique_ids:\n",
    "#         print(\"Processing patient: \" + str(id))\n",
    "#         index_positive = dataframe[(dataframe[id_column] == id) & (dataframe[label_column] == 1)].index\n",
    "#         index_negative = dataframe[((dataframe[id_column] == id) & (dataframe[label_column] == 0))].index\n",
    "#         random.seed(random_state)\n",
    "#         index_negative_sample = random.sample(list(index_negative), int(len(index_positive) * float(balance_ratio)))\n",
    "#         sample_indices = index_positive + index_negative_sample\n",
    "#         X = np.memmap('../00_Data/Dataframes/' + str(id) + '_features.npy', np.float32, mode='w+', shape=(len(sample_indices), window_length, 18))\n",
    "#         if extract_series:\n",
    "#             y = np.memmap('../00_Data/Dataframes/' + str(id) + '_label.npy', np.int16, mode='w+', shape=(len(sample_indices), window_length))\n",
    "#         else:\n",
    "#             y = np.memmap('../00_Data/Dataframes/' + str(id) + '_label.npy', np.int16, mode='w+', shape=(len(sample_indices), 1))\n",
    "#         bar = tqdm(total=len(sample_indices))\n",
    "#         i = 0\n",
    "#         for index in sample_indices:\n",
    "#             end_index = index + window_length # Calculate last idx of time window\n",
    "#             if (end_index <= len(dataframe)):\n",
    "#                 if(dataframe[id_column].iloc[index] == dataframe[id_column].iloc[end_index]):\n",
    "#                     seq_x = dataframe.drop(columns=[id_column, \"timestamp\", label_column]).iloc[index:end_index].values.tolist()\n",
    "#                     if extract_series:\n",
    "#                         seq_y = dataframe[label_column].iloc[index:end_index]\n",
    "#                     else:\n",
    "#                         seq_y = dataframe[label_column].iloc[end_index]\n",
    "#                     X[i] = seq_x # Append X of current time window to global list\n",
    "#                     y[i] = seq_y # Append y of current time window to global list\n",
    "#             bar.update(1)\n",
    "#             i += 1\n",
    "#         bar.close()\n",
    "#     return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
